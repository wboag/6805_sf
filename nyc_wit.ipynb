{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>What If Tool: Stop and Frisk Data</h1>\n",
    "\n",
    "This notebook downloads a subset of the Stop and Frisk data, builds a model to predict how likely that suspect is to be frisked (given that every suspect here has already been stopped), and loads the What If Tool to visualize these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install the What-If Tool widget if running in colab {display-mode: \"form\"}\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  !pip install --upgrade witwidget\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define helper functions {display-mode: \"form\"}\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Creates a tf feature spec from the dataframe and columns specified.\n",
    "def create_feature_spec(df, columns=None):\n",
    "    feature_spec = {}\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for f in columns:\n",
    "        if df[f].dtype is np.dtype(np.int64):\n",
    "            feature_spec[f] = tf.FixedLenFeature(shape=(), dtype=tf.int64)\n",
    "        elif df[f].dtype is np.dtype(np.float64):\n",
    "            feature_spec[f] = tf.FixedLenFeature(shape=(), dtype=tf.float32)\n",
    "        else:\n",
    "            feature_spec[f] = tf.FixedLenFeature(shape=(), dtype=tf.string)\n",
    "    return feature_spec\n",
    "\n",
    "# Creates simple numeric and categorical feature columns from a feature spec and a\n",
    "# list of columns from that spec to use.\n",
    "#\n",
    "# NOTE: Models might perform better with some feature engineering such as bucketed\n",
    "# numeric columns and hash-bucket/embedding columns for categorical features.\n",
    "def create_feature_columns(df, columns, feature_spec):\n",
    "    ret = []\n",
    "    for col in columns:\n",
    "        if feature_spec[col].dtype is tf.int64 or feature_spec[col].dtype is tf.float32:\n",
    "            ret.append(tf.feature_column.numeric_column(col))\n",
    "        else:\n",
    "            ret.append(tf.feature_column.indicator_column(\n",
    "                tf.feature_column.categorical_column_with_vocabulary_list(col, list(df[col].unique()))))\n",
    "    return ret\n",
    "\n",
    "# An input function for providing input to a model from tf.Examples\n",
    "def tfexamples_input_fn(examples, feature_spec, label, mode=tf.estimator.ModeKeys.EVAL,\n",
    "                       num_epochs=None, \n",
    "                       batch_size=64):\n",
    "    def ex_generator():\n",
    "        for i in range(len(examples)):\n",
    "            yield examples[i].SerializeToString()\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "      ex_generator, tf.dtypes.string, tf.TensorShape([]))\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(lambda tf_example: parse_tf_example(tf_example, label, feature_spec))\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    return dataset\n",
    "\n",
    "# Parses Tf.Example protos into features for the input function.\n",
    "def parse_tf_example(example_proto, label, feature_spec):\n",
    "    parsed_features = tf.parse_example(serialized=example_proto, features=feature_spec)\n",
    "    target = parsed_features.pop(label)\n",
    "    return parsed_features, target\n",
    "\n",
    "# Converts a dataframe into a list of tf.Example protos.\n",
    "def df_to_examples(df, columns=None):\n",
    "    examples = []\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for index, row in df.iterrows():\n",
    "        example = tf.train.Example()\n",
    "        for col in columns:\n",
    "            if df[col].dtype is np.dtype(np.int64):\n",
    "                example.features.feature[col].int64_list.value.append(int(row[col]))\n",
    "            elif df[col].dtype is np.dtype(np.float64):\n",
    "                example.features.feature[col].float_list.value.append(row[col])\n",
    "            elif row[col] == row[col]:\n",
    "                example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "\n",
    "# Converts a dataframe column into a column of 0's and 1's based on the provided test.\n",
    "# Used to force label columns to be numeric for binary classification using a TF estimator.\n",
    "def make_label_column_numeric(df, label_column, test):\n",
    "  df[label_column] = np.where(test(df[label_column]), 1, 0)\n",
    "\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Read training dataset from CSV {display-mode: \"form\"}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "sqf = pd.read_csv('https://raw.githubusercontent.com/wboag/6805_sf/master/nyc2003.csv')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "# https://www.quora.com/What-is-the-best-number-mathematically\n",
    "# 142857 received the most upvotes, and is therefore the best number\n",
    "random.seed(142857)\n",
    "\n",
    "\n",
    "# Ground turth (i.e. arrest or summons)\n",
    "\n",
    "label_column = 'frisked'\n",
    "#label_column = 'guilty'\n",
    "sqf[label_column] = np.where(sqf[label_column] == 'N', 0, 1)\n",
    "\n",
    "\n",
    "# Translate features into human-readable\n",
    "def is_guilty(row):\n",
    "    if row['sumissue']=='Y' or row['arstmade']=='Y':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def acproxm_readable(acproxm):\n",
    "    return acproxm\n",
    "    #return int(acproxm=='Y')\n",
    "\n",
    "def acevasv_readable(acevasv):\n",
    "    return acevasv\n",
    "    #return int(acevasv=='Y')\n",
    "\n",
    "def acincid_readable(acincid):\n",
    "    return acincid\n",
    "    #return int(acincid=='Y')\n",
    "\n",
    "def race_readable(race):\n",
    "    mapping = {'B':'Black','Q':'White Hispanic','W':'White','Z':'Other','P':'Black Hispanic','A':'Asian / Pacific Islander',\n",
    "               'X':'Unknown', 'I':'American Indian / Alaskan Native', ' ':'(not listed)'}\n",
    "    return mapping[race]\n",
    "\n",
    "def build_readable(build):\n",
    "    mapping = {' ':'(not listed)', 'H':'Heavy', 'M':'Medium', 'T':'Thin', 'U':'Muscular', 'Z':'Unknown'}\n",
    "    return mapping[build]\n",
    "\n",
    "def crime_subset(crime):\n",
    "    mapping = {'ROBBERY':'Robbery', 'CPW':'Possession of a Weapon',\n",
    "               'BURGLARY':'Burglary', 'BURG':'Burglary', 'GLA':'Grand Larcency Auto',\n",
    "               'CRIMINAL TRESPASS':'Trespass', 'CRIM TRES':'Trespass', 'CRIM TRESPAS':'Trespass', \n",
    "               'ASSAULT':'Assault', 'CPCS':'Possession of a Controlled Substance'}\n",
    "    if crime in mapping:\n",
    "        return mapping[crime]\n",
    "    else:\n",
    "        return 'Other Crime'\n",
    "    \n",
    "def premname_subset(premname):\n",
    "    include = [' ', 'SIDEWALK', 'CRIM TRESPASS', 'CPCS', 'CRIM TRES', 'CRIMINAL TRESPASS', 'ROBBERY', 'BURGLARY', 'GLA', 'CPW']\n",
    "    if premname in include:\n",
    "        return premname\n",
    "    else:\n",
    "        return 'Other Location'    \n",
    "\n",
    "def age_to_decade(age_s):\n",
    "    if age_s == ' ':\n",
    "        return -1 # random.random()*90\n",
    "        return '(null)'\n",
    "    age = int(age_s[0])\n",
    "    if age == 0:\n",
    "        return -1 # random.random()*90\n",
    "        return '(null)'\n",
    "    if age>90:\n",
    "        return 90\n",
    "        return '90+'\n",
    "    return age\n",
    "    return '%s0-%s9' % (age,age)\n",
    "\n",
    "def timestr_to_time(timestr):\n",
    "    match = re.search('(\\d+):(\\d+)', timestr)\n",
    "    if match:\n",
    "      hours,minutes = match.groups()\n",
    "      return int(hours) + float(minutes)/60\n",
    "    else:\n",
    "      return random.random() * 25\n",
    "    \n",
    "\n",
    "sqf[    'race'] = sqf[    'race'].apply(race_readable)\n",
    "sqf[   'build'] = sqf[  'build'].apply(build_readable)\n",
    "sqf['location'] = sqf['premname'].apply(premname_subset)\n",
    "sqf[     'age'] = sqf['age'].apply(age_to_decade)\n",
    "sqf['timestop'] = sqf['timestop'].apply(timestr_to_time)\n",
    "sqf[  'guilty'] = sqf.apply(is_guilty, axis=1)\n",
    "\n",
    "sqf['suspected_crime'] = sqf['crimsusp'].apply(crime_subset)\n",
    "sqf['near_scene_of_offense'] = sqf['ac_proxm'].apply(acproxm_readable)\n",
    "sqf['evasive_to_questions'] = sqf['ac_evasv'].apply(acevasv_readable)\n",
    "sqf['high-crime_area'] = sqf['ac_incid'].apply(acincid_readable)\n",
    "\n",
    "\n",
    "\n",
    "# After the above filtering, still only load 10,000 datapoints for the WIT\n",
    "sqf = sqf.iloc[:2000]\n",
    "\n",
    "\n",
    "\n",
    "# Get list of all columns from the dataset we will use for model input or output.\n",
    "input_features = ['age', 'sex', 'build', 'race', 'suspected_crime', 'location', \n",
    "                  'near_scene_of_offense', 'evasive_to_questions', 'high-crime_area', \n",
    "                  'timestop']\n",
    "#input_features = ['sex', 'age', 'race']\n",
    "features_and_labels = input_features + [label_column]\n",
    "\n",
    "features_for_file = input_features + ['guilty', 'frisked']\n",
    "\n",
    "\n",
    "sqf[input_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Create and train the classifier {display-mode: \"form\"}\n",
    "\n",
    "examples = df_to_examples(sqf, features_for_file)\n",
    "\n",
    "num_steps = 2000  #@param {type: \"number\"}\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "\n",
    "# Create a feature spec for the classifier\n",
    "feature_spec = create_feature_spec(sqf, features_and_labels)\n",
    "\n",
    "# Define and train the classifier\n",
    "train_inpf = functools.partial(tfexamples_input_fn, examples, feature_spec, label_column)\n",
    "classifier = tf.estimator.LinearClassifier(\n",
    "    feature_columns=create_feature_columns(sqf, input_features, feature_spec))\n",
    "classifier.train(train_inpf, steps=num_steps)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#@title Invoke What-If Tool for test data and the trained models {display-mode: \"form\"}\n",
    "\n",
    "\n",
    "num_datapoints = 10000  #@param {type: \"number\"}\n",
    "tool_height_in_px = 1000  #@param {type: \"number\"}\n",
    "\n",
    "from witwidget.notebook.visualization import WitConfigBuilder\n",
    "from witwidget.notebook.visualization import WitWidget\n",
    "\n",
    "# Setup the tool with the test examples and the trained classifier\n",
    "config_builder = WitConfigBuilder(examples[0:num_datapoints]).set_estimator_and_feature_spec(\n",
    "    classifier, feature_spec)\n",
    "WitWidget(config_builder, height=tool_height_in_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
